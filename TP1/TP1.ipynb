{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"mini-dataset/a1.png\", width=32, ALIGN=\"left\">\n",
    "<center>\n",
    "<h1>Mini Projets 2019-2020 (Info 232)</h1>\n",
    "Isabelle Guyon <br>\n",
    "info232@chalearn.org <br>\n",
    "</center>\n",
    "<span style=\"color:red\"> <h1> 1 . Workflow </h1> </span>\n",
    "    \n",
    "<p> Become a data scientist is one hour: learn about the basic workflow of data science:\n",
    "    <ol>\n",
    "        <li> Visualisation </li>\n",
    "        <li> Metric definition </li>\n",
    "        <li> Baseline results </li>\n",
    "        <li> Error bars </li>\n",
    "    </ol>\n",
    "    </p>\n",
    "</div>\n",
    "<div style=\"background:#FFFFAA\">\n",
    " This TP gives you 5 points if you answer well at least 5 questions. However we encourage you answer all questions: they are meant to give you ideas you can use later in your projects. If you cannot, get help by attending the Wednesday session.\n",
    "    \n",
    "<span style=\"color:red\"> <b>Save your notebook often with menu File + Save and Checkpoint.</b>\n",
    "<br> <b>Before you push your homework to your GitHub repo, use  Kernel + Restart and Run all.</b>\n",
    "</span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load general libraries\n",
    "import os, re\n",
    "from glob import glob as ls\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### Add path to the sample code so the notebook finds it:\n",
    "code_dir = 'code/'                        \n",
    "from sys import path; path.append(code_dir)\n",
    "#import utilities as ut\n",
    "from utilities import get_image\n",
    "from utilities import get_files\n",
    "# Import code that checks your answers\n",
    "from checker import check \n",
    "# Disable some warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\"> <h1> Step 1: Data visualisation and preprocessing </h1>\n",
    "    </div>\n",
    "    \n",
    "<p>\n",
    "This first par guides you through a example of reading and preprocessing a small image dataset. Read the code below and try to understand it.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = './mini-dataset'\n",
    "a_files = get_files(data_dir, 'a')\n",
    "b_files = get_files(data_dir, 'b')\n",
    "columns = 10\n",
    "rows = len(a_files+b_files)/columns\n",
    "fig = plt.figure(figsize=(columns, rows))\n",
    "k=1\n",
    "for filename in a_files+b_files:\n",
    "    img = get_image(filename)\n",
    "    fig.add_subplot(rows, columns, k)\n",
    "    plt.imshow(img) \n",
    "    plt.tick_params(axis='both', labelsize=0, length = 0)\n",
    "    plt.grid(b=False)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "Data often come already in a feature representation, but not always. As an exercise, we are going to guide you through a simple feature extraction process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Load an image\n",
    "\n",
    "1. Create a variable called `apple_example` and assign it the name of the first file in the list `a_files`. \n",
    "2. Create a variable `img` and assign it the corresponding image read from that file using the function `get_image`. \n",
    "\n",
    "`img` is a PIL image. PIL is a nice library to manipulate images, but data scientists often prefer using Numpy arrays. Fortunately it is easy to convert one to the other. \n",
    "\n",
    "3. Create a variable called `M` and assign it a <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html\">numpy array</a> containing `img` (this is called \"casting\"). Assign to three variables `imw`, `imh`, `nchannels` the dimensions (<a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html\">shape</a>) of `M`. \n",
    "4. Then print `imw`, `imh`, and `nchannels`. \n",
    "\n",
    "You will notice that there are 4 channels, what are those channels? Try to remember or check your class notes.\n",
    "\n",
    "Tip: To answer this kind of question, you need to read the documentation of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background:#00FF00\">CORRECT<br>:-)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Answer question 1\n",
    "question = 1\n",
    "import numpy as np         # This is needed to import Numpy\n",
    "apple_example = a_files[0]\n",
    "img = get_image(apple_example)\n",
    "M = np.array(img)\n",
    "imw, imh, nchannels = M.shape\n",
    "\n",
    "print(imw, imh, nchannels)\n",
    "plt.imshow(M) # This shows the image as a numpy array\n",
    "\n",
    "# This is the checker code, keep it\n",
    "answer = int.from_bytes(apple_example.encode('utf-8'), \"little\")+imw * imh + nchannels  \n",
    "score = 0\n",
    "score += check(answer, question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foreground and background colors\n",
    "The variable `white` has the color of pure white and a variable `red`the color of pure red (with transparency set to 255 in both cases).\n",
    "\n",
    "We can examine the colors of the foreground and the background as the channel values of `M[15, 15]`and `M[0, 0]` respectively. Do the color of the foreground and the background match your expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White = [255, 255, 255, 255]\n",
      "red = [255, 0, 0, 255]\n",
      "Foreground = [251   2   7 255]\n",
      "Background = [255 255 255   0]\n"
     ]
    }
   ],
   "source": [
    "white = [255, 255, 255, 255]\n",
    "red = [255, 0, 0, 255]\n",
    "print(\"White = {}\".format(white))\n",
    "print(\"red = {}\".format(red))\n",
    "print(\"Foreground = {}\".format(M[15, 15]))\n",
    "print(\"Background = {}\".format(M[0, 0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Separate color channels\n",
    "\n",
    "1. Define three arrays of type `float` named `R`, `G`, and `B`, containing the red, green and blue channels respectively (for all pixels)\n",
    "2. Then define an array `D` (color difference) containing `R-(G+B)/2` \n",
    "3. and an array `V` (value of intensity) containing `(R+G+B)/3`.\n",
    "\n",
    "Important: R, G, and B should be transformed to float to get correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background:#00FF00\">CORRECT<br>:-)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Answer to question 2\n",
    "question = 2\n",
    "R = M[:, :, 0]*1.\n",
    "G = M[:, :, 1]*1.\n",
    "B = M[:, :, 2]*1.\n",
    "D = R-(G+B)/2\n",
    "V = (R+G+B)/3\n",
    "\n",
    "# This is the checker code, keep it\n",
    "answer = np.sum(np.diag(D+V))\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Extraction of the `redness` feature\n",
    "\n",
    "1. Create a variable `redness` containing the average (mean) of `D` for the foreground pixels.\n",
    "\n",
    "Hint: The can be done by selecting the foreground pixels, i.e. those that are not `255` (white). You can do that with just one <a href=\"https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/BasicIndexing.html\"> advanced indexing</a> command.\n",
    "\n",
    "2. Check that your definition of redness matches `fg_r - (fg_g + fg_b)/2`. \n",
    "3. As a side question: try to define `whiteness = bg_r - (bg_g + bg_b)/2`. \n",
    "    1. Why do you get an error? \n",
    "    2. Why did you get no error for `fg_r - (fg_g + fg_b)/2`? \n",
    "    3. How can you do this \"right\"? Hint: rgb channels are defined as `integers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-88ac0511f52a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# This checks the correctness of your answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfg_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredness\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfg_r\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfg_g\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfg_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mbg_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Uncomment this to see that you get an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Answer to question 3\n",
    "question = 3\n",
    "redness = 0\n",
    "\n",
    "print(redness)\n",
    "# This checks the correctness of your answer\n",
    "fg_r, fg_g, fg_b, fg_a = M[15, 15]\n",
    "assert(redness == fg_r - (fg_g + fg_b)/2)\n",
    "bg_r, bg_g, bg_b, bg_a = M[0, 0]\n",
    "# Uncomment this to see that you get an error\n",
    "#whiteness = bg_r - (bg_g + bg_b)/2\n",
    "\n",
    "# This is the checker code, keep it\n",
    "answer = redness\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Extraction of the `elongation` feature\n",
    "\n",
    "1. Create two mean vectors `V0` and `V1` by averaging (taking the mean) of `V` along axis 0 and axis 1 respectively. \n",
    "2. Then use this line of code `V0_idx = [i for i in range(imw) if V0[i]!=255]` to get the indices of the values that are not white along axis 0 (horizontal). \n",
    "3. Similarly write code to extract `V1_idx` (pixels not white along axis 2, vertical).\n",
    "4. Extract from those information on the witdth `w` and the height `h` of the apple. \n",
    "5. Visually check that the width and height are correct. Finally compute the `elongation` variable (aspect ratio) as `w/h`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer to question 4\n",
    "question = 4\n",
    "\n",
    "V0 = np.zeros([imw])\n",
    "V1 = np.zeros([imh])\n",
    "V0_idx = [i for i in range(imw) if V0[i]!=255]\n",
    "V1_idx = [i for i in range(imh) if V1[i]!=255]\n",
    "w = 0\n",
    "h = 0\n",
    "elongation =0 \n",
    "print(w, h, elongation)\n",
    "\n",
    "# This is the checker code, keep it\n",
    "answer = w+h-elongation\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Function `extract_features`\n",
    "\n",
    "1. Write a function with `M` as an input argument and that takes all the steps we walked you through, then returns `redness` and `elongation` as a list. You will use the following template:\n",
    "\n",
    "```python\n",
    "def extract_features(M, verbose = True):\n",
    "# Put your code here.\n",
    "# verbose is just a flag you can use to comment out print statements needed to debug your code\n",
    "return [redness, elongation]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer to question 5\n",
    "question = 5\n",
    "\n",
    "def extract_features(M, verbose = True):\n",
    "    redness = 0\n",
    "    elongation = 0\n",
    "    return [redness, elongation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and visualize all the data\n",
    "To go a little bit faster, we give you the code to preprocess all the dataset in the next few cells. Check that you understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a big data matrix with all a_files and b_files\n",
    "verbose = False\n",
    "n = len(a_files)\n",
    "_X = np.zeros([2*n, 2])\n",
    "Y = np.zeros([2*n, 1])\n",
    "\n",
    "# Read and convert a_files\n",
    "for i in range(n):\n",
    "    if verbose: print(a_files[i])\n",
    "    img = get_image(a_files[i])\n",
    "    M = np.array(img)\n",
    "    _X[i, :] = extract_features(M, verbose)\n",
    "    Y[i] = 1 # Apples are labeled 1\n",
    "\n",
    "# Read and convert b_files\n",
    "for i in range(n):\n",
    "    if verbose: print(b_files[i])\n",
    "    img = get_image(b_files[i])\n",
    "    M = np.array(img)\n",
    "    _X[n+i, :] = extract_features(M, verbose)\n",
    "    Y[n+i] = -1 # Bananas are labeled -1\n",
    "\n",
    "# This is the checker code for question 5, keep it\n",
    "answer = np.sum(_X[1,:])+ np.sum(_X[-1,:])\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas data frames, heatmaps, and pairplot\n",
    "We already used Pandas dataframes in TP1. Data scientists like them too. Fortunately it is easy to move back and forth from Numpy arrays to Pandas dataframes. Pandas allows you to easily show arrays as heat maps.\n",
    "\n",
    "Sometimes datasets are large. You can create a heat map from the top row of your data frame with a command like `_XY.head().style.background_gradient(cmap='Blues')`. Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "column_names = ['redness', 'elongation', 'fruit']\n",
    "_XY = pd.DataFrame(np.append(_X, Y, axis=1), columns=column_names)\n",
    "_XY.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another way of making heatmaps that we showed you last time using Seaborn. Check the <a href=\"https://seaborn.pydata.org/generated/seaborn.heatmap.html\">searborn heatmap documentation</a> to figure out how to add annotations and change the color map.\n",
    "1. Try to make it look just like the one shown in class. \n",
    "2. Why are the colors in the second column so poorly contrated when you use seaborn heatmaps compared to the first method we showed to display Pandas dataframes as heatmaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "fig = plt.figure(figsize=(5,10))\n",
    "# Put your code here the create a seaborn heat map \n",
    "# looking like the one shown in class\n",
    "sns.heatmap(_XY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Feature standardization\n",
    "For better rendering and improved results, the features are often standardized. This means that for each column, we subtract the mean and divide by the standard deviation (except for the target).\n",
    "\n",
    "From the previous TP, do you remember some of the Pandas useful functions like `describe`? This allows you to quickly get statistics about your dataset. You can also use `mean` and `std`. Provide the mean and standard deviation of the features before and after standardization. Observe the effect of standardization on the heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 6\n",
    "\n",
    "# The library scikit-learn (sklearn) provides you code to standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "X = scaler.fit_transform(_X)\n",
    "XY = pd.DataFrame(np.append(X, Y, axis=1), columns=['redness', 'elongation', 'fruit'])\n",
    "\n",
    "# Change this code to make this heatmap look like the one in class\n",
    "fig = plt.figure(figsize=(5,10))\n",
    "sns.heatmap(XY)\n",
    "\n",
    "# Put your answers to question 6 here\n",
    "redness_mean_before, elongation_mean_before = 10, 10\n",
    "redness_std_before, elongation_std_before = 10, 10\n",
    "redness_mean_after, elongation_mean_after = 10, 10\n",
    "redness_std_after, elongation_std_after = 10, 10\n",
    "\n",
    "print(\"** BEFORE **\")\n",
    "print(\"redness: mean={0:5.2f}, std={1:5.2f}\".format(redness_mean_before, redness_std_before))\n",
    "print(\"elongation: mean={0:5.2f}, std={1:5.2f}\".format(elongation_mean_before, elongation_std_before))\n",
    "print(\"** AFTER **\")\n",
    "print(\"redness: mean={0:5.2f}, std={1:5.2f}\".format(redness_mean_after, redness_std_after))\n",
    "print(\"elongation: mean={0:5.2f}, std={1:5.2f}\".format(elongation_mean_after, elongation_std_after))\n",
    "\n",
    "# This is the checker code for question 6, keep it\n",
    "answer = redness_mean_before+elongation_mean_before+redness_std_before+elongation_std_before\n",
    "answer = answer - (redness_mean_after+elongation_mean_after+redness_std_after+elongation_std_after)\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplots\n",
    "Last time we also visualized data as pairplot, here is the pairplot of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(XY, vars=['redness', 'elongation'], hue='fruit', markers=[\"s\", \"o\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = XY.corr(method='pearson')\n",
    "sns.heatmap(abs(corr_mat), annot=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Feature selection\n",
    "Based on the pair plots and the correlation matrix:\n",
    "    - Which feature separates best the two fruit categories? \n",
    "    - Are the two features correlated or anti-correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 7\n",
    "\n",
    "number_of_best_feature = -1      # 0 for redness and 1 for elongation\n",
    "correlation_between_features = 0 # 1 for correlated and -1 for anti-correlated\n",
    "\n",
    "# This is the checker code for question 7, keep it\n",
    "answer = (1+ number_of_best_feature) * correlation_between_features\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For simplicity and because the dataset is tiny, we showed the feature standardization and feature selection steps on the whole dataset. However, those steps should normally be performed on training data first and then applied to test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\"> <h1> Step 2: Metric definition </h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Error rate and accuracy score\n",
    "\n",
    "1. Write a function that implements the error rate metric. Follow this template:\n",
    "\n",
    "```python\n",
    "def error_rate(solution, prediction):\n",
    "# Put your code here.\n",
    "return e\n",
    "```\n",
    "    \n",
    "2. Then write unit tests using the function `assert` that :\n",
    "    1. check that the error rate between `solution=Y` and `prediction=Y` is zero, \n",
    "    2. that between `solution=Y` and `prediction=np.zeros(Y.shape)` is one \n",
    "    3. and the between `solution=Y` and `prediction=np.ones(Y.shape)` is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer to question 8\n",
    "question = 8\n",
    "\n",
    "def error_rate(solution, prediction):\n",
    "    '''Compute the error rate between two vectors.'''\n",
    "    e = 0\n",
    "    return e\n",
    "\n",
    "# This is the checker code for question 8, keep it\n",
    "answer = error_rate(Y, Y) + error_rate(Y, np.zeros(Y.shape)) + error_rate(Y, np.ones(Y.shape))\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library `scikit_learn` also called `sklearn` has a function `accuracy_score` = `1-error_rate`. You can verify below that we get the same results on the unit tests proposed above. There are many <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html\">sklearn metrics</a>, we invite you to check them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#assert(error_rate(Y, Y) == 1-accuracy_score(Y, Y))\n",
    "#assert(error_rate(Y, np.zeros(Y.shape)) == 1-accuracy_score(Y, np.zeros(Y.shape)))\n",
    "#assert(error_rate(Y, np.ones(Y.shape)) == 1-accuracy_score(Y, np.ones(Y.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: The metric of your challenge\n",
    "The challenge you have chosen uses a particular metric. The metrics were chosen among: \"balanced_accuracy\", \"balanced_error_rate\", \"auc_metric\", \"f1_score\", \"mean_absolute_error\", and \"r2_metric\". Two important metrics to understand are the AUC (area under <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\">ROC curve</a> and the \"r2-metric\" or <a href=\"https://en.wikipedia.org/wiki/Coefficient_of_determination\">coefficient of determination</a>.\n",
    "\n",
    "Click on the <a href=\"http://saclay.chalearn.org/\">websites of this year challenges</a> and go to the \"Evaluation\" tab. Find what the metrics are. Learn about the metric of your own challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer to question 9\n",
    "question = 9\n",
    "\n",
    "gaiasavers_metric = \" \"\n",
    "xporters_metric = \" \"\n",
    "medichal_metric = \" \"\n",
    "\n",
    "# This is the checker code for question 9, keep it\n",
    "my_string = gaiasavers_metric+xporters_metric+medichal_metric\n",
    "answer = int.from_bytes(my_string.encode('utf-8'), \"little\")  \n",
    "\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\"> <h1> Step 3: Baseline results </h1></div>\n",
    "<p>\n",
    "We are now equipped to try some basic machine learning method to predict what fruit is shown on an image, based on \"redness\" and \"elongation\". We will again use `scikit-learn`. We will split the data into a training set and a test set and see how well we do with the nearest neighbor method. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one training-test split in a stratified manner. \n",
    "# \"Stratified\" means that we preserve the proportion of examples\n",
    "# of apples and bananas in the training and the test set.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "SSS = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n",
    "for train_index, test_index in SSS.split(X, Y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    Ytrain, Ytest = Y[train_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the training set (first line) and the test set (second line)\n",
    "columns = 10\n",
    "rows = len(a_files+b_files)/columns\n",
    "fig = plt.figure(figsize=(columns, rows))\n",
    "F = np.array(a_files + b_files)\n",
    "for k, filename in enumerate(np.concatenate((F[train_index],F[test_index])), start=1):\n",
    "    img = get_image(filename)\n",
    "    fig.add_subplot(rows, columns, k)\n",
    "    plt.imshow(img) \n",
    "    plt.tick_params(axis='both', labelsize=0, length = 0)\n",
    "    plt.grid(b=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and test data as heat maps:\n",
    "# (We show the whole code for inspiration...)\n",
    "XY_train = pd.DataFrame(np.append(Xtrain, Ytrain, axis=1), columns=['redness', 'elongation', 'fruit'])\n",
    "XY_test = pd.DataFrame(np.append(Xtest, Ytest, axis=1), columns=['redness', 'elongation', 'fruit'])\n",
    "\n",
    "fig =  plt.figure(figsize=(5,5))\n",
    "fig.subplots_adjust(wspace=1)\n",
    "ax_train = fig.add_subplot(1, 2, 1)\n",
    "sns.heatmap(XY_train, annot=True, fmt='.1f', cmap='RdYlGn')\n",
    "ax_train.title.set_text('Training')\n",
    "\n",
    "ax_test = fig.add_subplot(1, 2, 2)\n",
    "sns.heatmap(XY_test, annot=True, fmt='.1f', cmap='RdYlGn')\n",
    "ax_test.title.set_text('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our own kind of scatter plot...\n",
    "from utilities import make_scatter_plot\n",
    "\n",
    "# Check that this is the same as what we get with pair plots.\n",
    "make_scatter_plot(X, F, train_index, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: One nearest neighbor\n",
    "The 1-nearest neighbor classifier is a nice and simple method. Luckily it is implemented in `scikit-learn`. You may also want to implement it yourself as part of your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `KNeighborsClassifier` classifier from `scikit-learn`. \n",
    "2. Instanciate a classifier of that class and set the number of neighbors to one. \n",
    "3. Train a model with `Xtrain` by calling the method `fit`. \n",
    "4.  Then use the trained model to create two vectors of prediction `Ytrain_predicted` and `Ytest_predicted` by calling the method `predict`. \n",
    "5. Compute `e_tr`, the training error rate, and `e_tr` the test error rate.\n",
    "\n",
    "**WARNING:** `scikit-learn` uses lists for prediction labels instead of column vectors. You will have to replace `Ytrain` by `Ytrain.ravel()` and `Ytest` by `Ytest.ravel()` to avoid an error message and wrong error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer to question 10\n",
    "question = 10\n",
    "\n",
    "### Put your code here\n",
    "Ytrain_predicted = np.ones(Ytrain.shape).ravel()\n",
    "Ytest_predicted = np.ones(Ytest.shape).ravel()\n",
    "e_tr = 0.5\n",
    "e_te = 0.5\n",
    "\n",
    "# This is the checker code for question 10, keep it\n",
    "print(e_tr, e_te)\n",
    "answer = e_tr + e_te\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "We can also extract the variables `tn`, `fp`, `fn`, `tp` (true negative, false positive, false negative, and true positive) using the `confusion_matrix` function of `scikit_learn`, for test data predictions. With these values, you can calculate the balanced error rate (`BER`) using the formula seen in class and verify that it gives the same result as `1-balanced_accuracy`.\n",
    "\n",
    "We also provide in `utilities.py` the function `plot_confusion_matrix`, which is in the latest version of scikit-learn (not necessarily in the one you have)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from utilities import plot_confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Ytest.ravel(), Ytest_predicted).ravel()\n",
    "print(\"TP={}, FP={}, FN={}, TP={}\".format(tn, fp, fn, tp))\n",
    "print(\"Balanced error rate as 0.5*(fp/(tn+fp)+fn/(tp+fn))= {}\".format(0.5*(fp/(tn+fp)+fn/(tp+fn))))\n",
    "print(\"Balanced error rate as 1-balanced_accuracy = {}\".format(1-accuracy_score(Ytest.ravel(), Ytest_predicted)))\n",
    "\n",
    "class_names = np.array([\"apple\", \"banana\"])\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(Ytest.ravel(), Ytest_predicted, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(Ytest.ravel(), Ytest_predicted, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's overlay the predictions on the scatter plot ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_scatter_plot(X, F, train_index, test_index, predicted_labels=Ytest_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... then show the \"ground truth\"\n",
    "We see that there is one apple that was classified as a banana (i.e. one \"false negative\" since the banana class is the \"negative\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_scatter_plot(X, F, train_index, test_index, predicted_labels='GroundTruth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\"> <h1> Step 4: Error bar </h1></div>\n",
    "<p>\n",
    "    To compute the error bar we repeat multiple times the train/test split and compute the mean and standard deviation of the test error. This takes into account both the variability of the training set and that of the test set. But is is known to be a biased estimator of the error variability because there is a large overlap between the training sets and the test sets in each split. However, it is pretty much the best we can do to compute error bars.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "n = 10\n",
    "SSS = StratifiedShuffleSplit(n_splits=n, test_size=0.5, random_state=5)\n",
    "E = np.zeros([n,1])\n",
    "k = 0\n",
    "for train_index, test_index in SSS.split(X, Y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    Ytrain, Ytest = Y[train_index], Y[test_index]\n",
    "    neigh.fit(Xtrain, Ytrain.ravel()) \n",
    "    Ytrain_predicted = neigh.predict(Xtrain)\n",
    "    Ytest_predicted = neigh.predict(Xtest)\n",
    "    e_te = error_rate(Ytest.ravel(), Ytest_predicted)\n",
    "    print(\"TEST ERROR RATE:\", e_te)\n",
    "    E[k] = e_te\n",
    "    k = k+1\n",
    "    \n",
    "e_te_ave = np.mean(E)\n",
    "print(\"\\n\\nMEAN ERROR RATE ={0:5.2f}\".format(e_te_ave))\n",
    "print(\"STANDARD DEVIATION ={0:5.2f}\".format(np.std(E)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Your final score is %d / 10, congratulations!' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "<span style=\"color:red\">\n",
    "<br>\n",
    "    To finalize your homework:\n",
    "<b>\n",
    "<ul>\n",
    "    <li> Use  Kernel + Restart and Run all.</li>\n",
    "    <li> Save your notebook.</li>\n",
    "    <li> Push your changes to your GitHub repo with:</li>\n",
    "</ul>   \n",
    "</b>\n",
    "<pre>\n",
    "git add .\n",
    "git commit -m 'my homework is done'\n",
    "git push\n",
    "</pre>\n",
    "<br>\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
